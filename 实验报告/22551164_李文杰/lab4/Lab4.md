# Lab4: Hexagon NPU GEMM

## 实验数据

| 实验编号 | 实现方式 | 设备/模拟器 | 矩阵尺寸 (M×K×N) | 计算耗时 (ms) | 备注 |
|---:|---|---|---:|---:|---:|
| 1 | 朴素 baselines | 设备 | 64×64×64 | 45.217 |  |
| 2 | HVX 内积 (A * B^T) | 设备 | 64×64×64 | 28.495 |  |
| 3 | HVX 外积 (A * B) | 设备 | 64×64×64 | 40.118 |  |
| 4 | 朴素 baseline | 设备 | 256×256×256 | 505.334 |  |
| 5 | HVX 内积 (A * B^T) | 设备 | 256×256×256 | 51.276 |  |
| 6 | HVX 外积 (A * B) | 设备 | 256×256×256 | 66.841 |  |
| 7 | 朴素 baseline | 设备 | 512×512×512 | 7258.736 |  |
| 8 | HVX 内积 (A * B^T) | 设备 | 512×512×512 | 128.224 |  |
| 9 | HVX 外积 (A * B) | 设备 | 512×512×512 | 295.391 |  |
| 10 | 朴素 baseline | 设备 | 88×99×66 | 56.912 |  |
| 11 | HVX 内积 (A * B^T) | 设备 | 88×99×66 | 32.347 |  |
| 12 | HVX 外积 (A * B) | 设备 | 88×99×66 | 45.063 |  |

## 实验分析

分析要点：

1. 对比内积与外积在数据复用、内存访问模式与向量指令使用上的差异；
2. 关键 HVX 指令详解：指出在代码中使用到的每种 HVX 指令（例如 Q6_V_vsplat_R、Q6_Vqf32_vmpy_VsfVsf、Q6_Vqf32_vadd_Vqf32Vqf32、Q6_V_vror_VR 等）并解释它们在你的实现中如何改善性能；
3. 针对尾部、对齐、缓存与内存带宽瓶颈提出优化建议。

### 1. 内积与外积对比

#### 算法形态与主要循环结构

- **外积：按 `i`（行）和 `j`（列向量块）循环，在 `k` 方向对 `A[i][k]` 的标量做广播，再与 `B[k][j:j+31]` 向量相乘并累加到 `C[i][j:j+31]`。
   示例片段（向量块级别）：

  ```
  /* 对每个 i, 每个 j-block: */
  hvx_vec_t acc = hvx_vzero();
  for (uint32_t l = 0; l < K; ++l) {
      float a_scalar = A[i*K + l];
      hvx_vec_t a_bcast = hvx_vsplat_floatbits(a_scalar);
      hvx_vec_t b_vec = hvx_load_f32_aligned(B + l*N + j);
      hvx_vec_t mul = Q6_Vqf32_vmpy_VsfVsf(a_bcast, b_vec);
      acc = Q6_Vqf32_vadd_Vqf32Vqf32(acc, mul);
  }
  hvx_store_f32_aligned(C + i*N + j, Q6_Vsf_equals_Vqf32(acc));
  ```

- **内积：按 `i` 和 `j` 循环，对 `k` 做向量化；对每个 `C[i][j]` 加载 A 的一段向量 `A[i,l:l+31]` 与 `B^T[j,l:l+31]` 做逐元素乘并在向量域累加，最后把向量累加规约为标量写入 `C[i][j]`。
   示例片段（逐块 k）：

  ```
  hvx_vec_t acc = hvx_vzero();
  for (uint32_t bl = 0; bl < k_blocks; ++bl) {
      hvx_vec_t a_v = hvx_load_f32_aligned(A + i*K + l);
      hvx_vec_t b_v = hvx_load_f32_aligned(B_T + j*K + l);
      acc = Q6_Vqf32_vadd_Vqf32Vqf32(acc, Q6_Vqf32_vmpy_VsfVsf(a_v, b_v));
      l += VLEN;
  }
  float vec_sum = hvx_reduce_sum_qf32(acc);
  /* handle tail k%VLEN by scalar */
  ```

#### 数据复用

- **外积优势**：
  - 每次处理 `A[i][l]` 的一个标量，并把它广播到一整段 `VLEN` 元素，**同一个标量在 N 方向的多个向量块上重复使用**（每个 `l` 对应的 A 标量参与更新 `N / VLEN` 个向量块的 C）。
  - B 的每个元素 `B[l][j..]` 在同一个 `l` 循环中只被加载一次用于那一 `j` 块，且同一个 B 块不会为了多个 `l` 重复加载（按实现）。
  - 总结：外积极利于**A 标量重用**，对 A 的读带宽压力小；适合 K 较大、N 较大的情形（广播带来高计算密度）。
- **内积特点**：
  - 在当前实现的循环顺序（i, j, 处理 k-blocks）下，**A 的向量段会为每个 j 重复加载**，即 A 的相同向量段在不同 j 上没有被复用（除非改变循环顺序或做块化）；B^T 的一行（即原 B 的一列）同样在不同 i 上会被重复加载。
  - 若改循环顺序/引入 tiling（例如对 j 做小块内循环），可以让 A 的向量段在该 j 块内被复用，从而提升内存效率。
  - 总结：内积本质上能同时对 A、B 批量读取并做向量化乘加，但是否产生**有效复用**取决于循环排列和分块策略。

#### 内存访问模式与带宽

- **外积**：
  - 访问模式：按 `l` 顺序访问 B 的整行 B[l][0..N-1]（按块分块读），对 C 写按块顺序写入；A 的访问为顺序逐元素（标量）。
  - 带宽特点：B 的读取按块对齐较好（若 B 按行存放且对齐），C 的写按连续向量块写；A 的读取带宽小。
  - 更容易获得高内存带宽利用率（一次加载 32 个 float）。
- **内积**：
  - 访问模式：若 B 已转置为 N×K（按行存放 B^T），对 B^T 的访问是按行连续（对 j 不同），这对 B^T 有利；但 A 的行段若在 j 循环内多次加载将造成重复带宽消耗。
  - 必须配合循环块化（block/tile）或缓存友好布局才能获得和外积相当的带宽效率。

#### 指令/寄存器利用差异

- 外积多使用 **标量广播**（vsplat） + **向量 load**（B） + **向量 mul/add**，每次乘加使用 32 元素并行，能够把 A 的标量操作摊薄到很多并行乘法中；内积则更多地使用 **两个向量 load** + mul/add，随后进行**向量规约**（rotate-add chain），规约步骤会产生额外指令开销与延迟。
- 因此：外积在减少规约开销、降低对横向加和指令依赖方面更有优势；内积则在需要最终单标量结果时不可避免需要规约，规约步骤的代价要计入总成本。

### 2. 关键 HVX 指令

#### 1) `Q6_V_vsplat_R(int32_t scalar_bits)` — 标量广播

- **功能**：把一个 32-bit 值（这里是 float 按位表示）复制到向量寄存器的所有通道，得到一个长度为 32 的向量，其中每个 lane 都是相同的浮点值。

- **用途**：外积实现中把 `A[i][l]` 的单个 float 广播成向量，然后与 `B[l][j:j+31]` 做逐元素乘法。

- **性能贡献**：把对 `A` 的单个标量乘法扩展为 32 次并行乘法，从而极大提高了算术密度（一条乘法指令相当于 32 次浮点乘）。

- **示例**：

  ```
  float a_scalar = A[i*K + l];
  hvx_vec_t a_bcast = Q6_V_vsplat_R(float_to_bits(a_scalar));
  ```

#### 2) `Q6_Vqf32_vmpy_VsfVsf(HVX_Vector a, HVX_Vector b)` — 向量逐元素乘

- **功能**：对两个向量寄存器做逐元素乘法，返回 QF32（高精度/扩展）格式的向量结果。

- **用途**：外积和内积里都用到，用于并行完成 32 个浮点乘。

- **性能贡献**：把 32 次浮点乘放到一条指令内完成；返回的 QF32 有助于累加时降低精度损失/溢出风险。

- **示例**：

  ```
  hvx_vec_t mul = Q6_Vqf32_vmpy_VsfVsf(a_bcast, b_vec);
  ```

#### 3) `Q6_Vqf32_vadd_Vqf32Vqf32(HVX_Vector x, HVX_Vector y)` — 向量逐元素加

- **功能**：逐元素 add，用于把新的乘积加到累计向量（QF32）。

- **用途**：累加 `mul` 到 `acc`。

- **性能贡献**：以向量化方式并行完成累加，保持向量域的高吞吐量，避免在每次乘法后做标量化。

- **示例**：

  ```
  acc = Q6_Vqf32_vadd_Vqf32Vqf32(acc, mul);
  ```

#### 4) `Q6_V_vror_VR(HVX_Vector v, int rotate_bytes)` — 向量循环右移

- **功能**：把向量中的字节循环左移指定字节数，用于实现向量内元素之间的交互（常用于横向规约 / reduction）。

- **用途**：在规约函数中配合 `vadd` 做逐步折半相加（例如先右移 16 个 float，再 8、4、2、1 以完成所有 lanes 的求和）。

- **性能贡献**：规约时只需要对向量进行几次 `vror` + `vadd` 即可把 32 个元素合并到每个 lane 的同一值，再转回标量。相比纯标量循环规约，指令数和延迟显著更低。

- **示例**（规约步骤）：

  ```
  tmp = Q6_V_vror_VR(acc, 16 * sizeof(float));
  acc = Q6_Vqf32_vadd_Vqf32Vqf32(acc, tmp);
  /* 然后 8,4,2,1 */
  ```

#### 5) `Q6_Vsf_equals_Vqf32(HVX_Vector qf32)` — QF32 → SF 转换

- **功能**：把高精度 QF32 向量转换为 SF（标准 float）向量。

- **用途**：累加完成后把累加器从 QF32 转为通用可存储的 SF 向量，然后直接写回内存（存 `C[i][j..]` 的向量）。内积实现中也在最终规约后把 QF32→SF 后取 lane0。

- **性能贡献**：避免在每次乘加中转换格式，减少格式转换频次；保持累加在更高精度域可以减少中间误差/溢出。

- **示例**：

  ```
  hvx_vec_t out_sf = Q6_Vsf_equals_Vqf32(acc);
  hvx_store_f32_aligned(C + i*N + j, out_sf);
  ```

#### 6) 对齐加载/存储

- **实现策略**：对齐检测后直接内存映射为 `HVX_Vector` 读取，若非对齐则 `memcpy` 到对齐缓冲区再读写。
- **性能贡献**：保证在硬件要求对齐下使用整寄存器读写，避免非对齐逐元素访存开销或异常路径；通过避免大量非对齐访问来提升带宽利用率和指令吞吐。

### 3. 针对尾部、对齐、缓存与内存带宽瓶颈的优化建议

#### A. 尾部处理

- 问题：目前尾部由标量循环处理（`n%32` 或 `k%32`），这在尾部占比较大时会拖慢总速。
- 建议：
  1. **使用掩码**——可在不回退到纯标量的情况下加载不完整向量并进行向量化操作。若 HVX 没有原生 masked load，可采用 `memcpy` 小块到对齐临时区后再向量化处理（已在代码中部分实现）。
  2. **处理为小块**：在分配或在运行时为输入/输出分配多 0 的填充（padding）使得 N 或 K 向上对齐到 VLEN，这样主循环不需尾部判断，尾部可以在最后一次写回时裁剪或直接写入多余位置（如果允许覆写填充区域）。
  3. **对尾部常见大小做小型向量化 epilogue**：为常见的 remainder（1..31）实现一套小向量化路径（例如用半向量 16、8、4 的步骤），减少纯标量比例。

#### B. 对齐

- 问题：非对齐加载会发生 `memcpy` 到临时对齐缓冲区，产生额外开销。
- 建议：
  1. **确保输入/输出在创建时就对齐**：测试和部署时用 `posix_memalign`（或平台等价）为矩阵分配对齐内存，避免运行时 `memcpy`。在测试代码中已使用 `posix_memalign`。
  2. **在数据布局层面保证对齐**：当构造 B^T（转置）时，按行填充并确保行首地址是 128 字节对齐（可以为每行增加 padding 或存储为连续对齐的块），便于连续向量加载。
  3. **批量转置/打包**：如果输入 B 原始不对齐且无法控制分配，先把 B 转置并 pack 到一个对齐的缓冲区（一次性拷贝成本小于运行时多次 `memcpy` 的总和）。

#### C. 缓存（L1/L2）友好性与 tiling

- 问题：所有向量化优势只有在数据进入缓存后才能发挥；若数据集超出缓存并频繁触发 L2/L3 访问，带宽成瓶颈。
- 建议：
  1. **块化**：对 i、j、k 三维做块化。例如对 i 做行块、对 j 做列块、对 k 做累加块（例如 `Mb x Nb x Kb`），这样可以把 B 子块或 A 子块保留在 L1/L2 中更久，减少内存读取次数。
     - 经典策略：对 C 的小 tile 采用外积或内积方式更新，使得相同的 A 子块在更新多个 C 列块时被复用。
  2. **优先保证向量块在缓存中**：把 `k` 的块大小设置为能被 L1 缓存容纳（考虑每次读取 B 子块和 A 子块的总大小），以便在内层循环中重复利用。
  3. **对 B 做预先打包（pack）**：按 tile 格式把 B 或 B^T 打包到连续对齐的临时区域，便于向量连续加载（减少 TLB/缓存冲突）。

#### D. 内存带宽与预取

- 问题：在内存带宽受限时，计算不能填满管线导致性能受限。
- 建议：
  1. **显式预取**：在进入内层循环前预取后续要用的 B 子块或 A 子块，给 L2 有时间把数据装载到 L1。实验时记录 L2 miss 与带宽利用率。
  2. **减少不必要的写**：在外积实现中可推迟写回或合并写操作（例如在寄存器 / 向量缓冲区累积更多步再写），减少写占用带宽。
  3. **内存访问顺序优化**：确保大块顺序访问（连续地址）以便硬件顺序读写和 DMA 合并。